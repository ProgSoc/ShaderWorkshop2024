<!DOCTYPE html>
<head>
<!-- highlight.js -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@11.9.0/build/styles/default.min.css">
<script src="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@11.9.0/build/highlight.min.js"></script>
<!-- GLSL -->
<script src="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@11.9.0/build/languages/glsl.min.js"></script>
<script>hljs.highlightAll();</script>


<!-- KaTeX -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/katex.css" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/katex.js" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/contrib/auto-render.min.js" crossorigin="anonymous" onload="renderMathInElement(document.body);"></script>
</head>

<h1>Introduction to Shaders (2024)</h1>

This post will introduce you to some of the basics of writing shaders, small programs that run on the GPU to determine the colour of each pixel on the screen.
While most modern quad-core CPUs can run 8 threads in parallel, GPUs can often handle thousands. A shader allows us to write code that runs across all of these cores as separate instances of the same program (known as invocations). This post will mainly focus on OpenGL's GLSL 300 ES shader language however these skills should apply to most shader languages, graphics libraries and game engines.

<h2> Introduction to GLSL </h2>
<h3> Syntax and Semantics </h3>
GLSL is a C-like language with a few differences such as the lack of pointers and the addition of vector and matrix types. Here is a sample of some of the syntax features:

<pre>
<code class="language-glsl">#version 300 es

float square(in float x) {
    return x * x;
}

struct Foo {
    mat4 bar;
    vec3 baz;
};

void main() {
    vec4 red = vec4(1.0, 0.0, 0.0, 1.0);

    if (red.r == 1.0) {
        while (true) {
            break;
        }
    }

    #define PI 3.14159

    #ifdef PI
        for (int i = 0; i < 10; i++) {
            continue;
        }
    #endif
}
</code>
</pre>

<h3> Fragment Shaders </h3>
The first type of shader we will be looking at is the fragment shader. A fragment shader will have 1 invocation responsible for determining the colour of 1 fragment (in most cases a fragment is a pixel).

<iframe height="350" width="800" src="https://jaspwr.github.io/spectra/?embedded=true&startPaused=true&project=eJytlV1vmzAUhv%2BK5d20Gs2MgQCpdlWt29U%2B1MumijxwiCWwkTFpoyj%2FfcdAEgpp2mrNBQr2%2BXgfH5%2FDFktWcDzD34rSbLCDM8XyCs%2FuHxxcrVjKtX3Z4qXIeWdZMCEnS80ysE6UNFwasMGf1mArlEQeIYhXczmXpeaJaNZWIluVaJkrZq7tjqoNWvPER7cQ50blSjfLayVSZONfXKLtXCL4HQzQ18bjgkxcB5FJYB%2FUQe6EXILvDu%2BcsUqQZF5VKWQrpVSVMLB1fZBHUb2%2BUUqn1UCd%2FXdQuLcBgRf7GJOnDfrcaPtCJ%2BS6Nczyxe9uH2x76XZziXdw4KUoeS4k%2F65ZucKzLZYq5e35ixTEA7o%2FjQPP8wM3iDxCYx%2FozKa0wBlXBTfa1nAf2oZ4wjPXd%2BG48AbPKCE7B6fMMLuVs78873kim%2B4Y8C7RnEv0p2YpLNZSLJUufsH5adGqeoBYSotMQKJ7WxECDAVnVa15ahM8itQAh%2Bt5Dl5xuAIGXqgLbhXPeWKs1RKuGwdNUGYIlHULtpgd8pQSSj13GnohJTGJesT5ValVplkxZgaHhtg9TXzwbJnfDEKPIFH4Pg7f96BmlAY0JlMv6lXuUchUPY4Z%2FNjr6ubS4ARF6%2Fcugig8AvjkGYDR9Vn9HpQxjF1Q7sc0hCt4BGgHxRggOleD1ml%2F59q3O1XrhN9CF%2F8czpo3AlLaK1FI31ciGkYx3M%2Bp57thRAP3dUJAaxD%2FD7AZUx8FaAcJT7NublRNwhdnR7v9g8k0t0aLBUy%2BsrYz0zCdcfNiBza7B7%2Fe7GmO8mlzZSUsFiey7nNcjQP3wgyhnGcoJxS9ieRUDz4ngeMfMwzT9RCGERv%2F8%2BJPNdIH1aH7Kg%2F1jzKeqUEX4jzCiUb5IILuiz0kGCY8A9BFGHUFdErBEq3aL9c%2FwTLBlA%3D%3D" style="border: none; display: block"></iframe>

<p>
Here we can see the output colour being set to a constant value so every pixel will be the same colour. Colours are defined as <code>vec4</code>s representing the <code>r</code>, <code>g</code>, <code>b</code> and <code>a</code> channels. Note that the brightnesses are from <code>0.0</code> to <code>1.0</code>.
</p>

<p>
Now let's try using some UV coordinates. We'll get to where these come from and how to set them later but for now we'll just set them to a <code>vec2</code> representing the position of the fragment on the screen. UV coordinates are normalised so they range from <code>0.0</code> to <code>1.0</code> in both the x and y directions where <code>(0.0, 0.0)</code> is the bottom left of the screen and <code>(1.0, 1.0)</code> is the top right. Note the y-axis is flipped from what you're probably used to.
</p>
<iframe height="350" width="800" style="border:none; display: block;" src="https://jaspwr.github.io/spectra/?embedded=true&startPaused=true&project=eJytlV1vmzAUhv%252BK5d20GsmMgQCpdlWt29U%252B1MumirzgEEtgI2PSRlH%252B%252B46BJBTStNGaq2Cfj%252Ffx8TneYslyjqf4W16YDXZwqlhW4unDo4PLFUu4th9bvBQZby1zJuR4qVkK1gslDZcGbPCnNdgKJZFHCOLlTM5koflC1Gsrka4KtMwUMzd2R0i05guKqvWtUjopYVFVxq756A5C36pM6dpyrUSCbMqra7SdSQS%252FgwH6Wntc7aM4iIxjB7ljcg2%252BO7xzhsJBpXlTeCPPR4UqhYGto7wXkrvq7L%252BDwr0NCLzaxxg%252Fb9DnWtsXOiY3jWGazX%252B3%252B2DbSbebSbyDGhSi4JmQ%252FLtmxQpPt1iqhDclEQmIJ2PXn8SB5%252FmBG0QeobEPdGZTWOCUq5wbbcu6D21DPOOp67vjwMEbPKWE7BycMMPsVsb%252B8qzjiWy6Y8D7heZcoj8VS2CxkmKpdP4Lzk%252BLRtUjxFJapAISPRBIQYAh56ysNE9sgieRGOBwPc%252FBKw63wsAHdcGt5BlfGGu1hBvIQROUGQKl7YItZos8oYRSz52EXkhJTKIOcTYqtEo1y4fM4FATu6eJD54N87tB6BEkCi%252Fj8H0PakZpQGMy8aJO5Z6ETNTTkMGPvbZuLg1OUDR%252BFxFE4RHAJ5cBeFDHMHZBuh%252FTEO7gkaAZHkOC6FwRGqf9pWu%252B7lWlF%252FwO2vhnf%252F68k5DSTo1CehkiDaMYLujE890wooH7NiGg1Yj%252FB1jPqY8CtJOEJ2k7OMo64avDo9n%252BwWSSWaP5HEZfUdmhaZhOuXm1Bevdg19n%252BNRH%252BbwZWQnz%252BYms%252BxyjYeBOmD6U8wLlhKJ3kZxqwpckcPxDhn66DkI%252FYu1%252FXvypRvqgOrQvdV%252F%252FIOOZGrQhziOcaJQPImif7D5BP%252BEZgDbCoCugU3K20Kp5uv4BRWDKrg%253D%253D&startIdle=false&defaultSourceFile=main.frag"></iframe>

<h3> Swizzling </h3>
A very useful language feature that is unique to shader languages is swizzling. Swizzling allows for any combination of a vector's elements to be used in any order. For example:


<pre>
<code class="language-glsl">/* ... */

void main() {
    vec4 foo = vec4(1.0, 2.0, 3.0, 4.0);
    vec3 bar = foo.xww; // bar := [1.0, 4.0, 4.0]
    foo.xy += vec2(1.0, 1.0) // foo := [2.0, 3.0, 3.0, 4.0]
    vec3 baz = vec3(foo.xy, 0.0); // baz := [2.0, 3.0, 0.0]
}
</code>
</pre>
In addition to <code>x</code>, <code>y</code>, <code>z</code> and <code>w</code>, you can also use <code>r</code>, <code>g</code>, <code>b</code> and <code>a</code> when dealing with colours. Both ways are equivalent.

<h3> Uniforms </h3>
Sometimes we may want to pass some parameters into our shader. For basic fragment shaders like what we have defined above, this may be things like the time as a <code>float</code> or the screen size as a <code>vec2</code> to convert UV coordinates to pixel coordinates. We can define these as uniforms.

<iframe height="350" width="800" src="https://jaspwr.github.io/spectra/?embedded=true&project=eJytlltvmzAUgP%2BK5b2kG8lsAwFS7ana5WkX9bGpIhccYgkwMiRtVOW%2F7xhIQoGmydY%2BFZ%2Fr53OJn3HGU4Fn%2BGual1ts4VjxpMCzu3sLFyseCW0%2BnvFSJqLRTLnMJkvNY9AOVVaKrAQd%2FGEDulJlyCYEiWKezbNci1BWZysZr3K0TBQvr41kncml0ml9gkqZCjhW6xJtROigb%2BD8RiVKV7obJSNkgo6u0PM8Q%2FBXm2n0BfGHYlSAyLi4urpui%2BNGHKqiEqOPiE7cg9IhCKiZqCNtodhCZOJaoEeM2g7vrD46cJZvosusRslVIUsQHfEYWm9ulNJR0aEz%2Fx0I9zqQ3GjvY%2FK0RZ%2Bq3D6zCWkw4mTxu5GDbivcbp7hHVQxl7lIZCa%2Ba56v8OwZZyoSdVFlBMmTCXWmgWvbjktd3yYscICu3OYGOBYqFaU2jbF3bVw84Rl14DItvMUzRsjOwhEvuREl%2FEEkLUtkwh0d3oZaiAz9WfMIDps2%2BAX3p2Wd1T34UlrGEgLdmWIQYEgFL9ZaRCbAo4xK4KC2beGVgL4q4YNRMCtEIsLSaC2hhwXkBCUGR3FzYIrZIE8ZYcymU8%2F2GAmI3yJOxrlWseZpnxkMKmI6THywrJnPBmFHEN%2B7jMNxbKgZYy4LyNT2W5V7lFmkHvsMTmA3daPMHaCo7S4i8L0jgEMuA7Chjl5AIXUnYB704JGgXj99Av9UEWqjfdPVX7dqrUPxDcb4Z3eDnUnIWLtG%2FmWIzPMDaNCp7VDPZy59mxDQKsT%2FA6z21L8AeqwP2OLxKaHEpTTw3YC4rMXTjHMfaMwaIuoOMe1%2FDV6uCrOzzx6iaTt%2FZ2cWn4jiZs8V1f28uutq8Q%2BeRYlRWixgU%2Bdrs%2BNLrmNRvroxKunBrrUrq5t62o5NCovFQNR9jHHfccvNQA1aKAMZnUUytDNeksBt9xm64VoIXY%2BV%2Fenkh%2Bb%2BnerQPE26%2BfcinqhB4%2BI0wsBcvxNB88LoEnQDngBoPJwGGBjkswAGd%2FZLgmp2%2BwTdiC2CntN6%2FM1zIOWhVvXb4C9xG0PB" style="border: none; display: block"></iframe>

<p>
Now the colour of our window should change over time. The way you pass these in will depend on what OpenGL implementation you're using.
</p>


<h3> Textures </h3>
Of course we need be able to load in some textures. Textures are passed into the shader as <code>sampler2D</code> uniforms and then samples can be taken from them using the <code>texture</code> function. <code>texture</code> takes in a <code>sampler2D</code> and a <code>vec2</code> of the UV coordinates and gives us the colour at that position as a <code>vec4</code>. Recall that the UV coordinates range from <code>0.0</code> to <code>1.0</code> and <code>(0.0, 0.0)</code> is the bottom left of the texture and <code>(1.0, 1.0)</code> is the top right. These coordinates do not correspond to actual pixels in the texture. This is because the texture is interpolated between the pixels to give a smooth result when displayed at different sizes (for linear <a href="https://www.khronos.org/opengl/wiki/Sampler_Object#Filtering">filter mode</a>).

<iframe height="350" width="800" src="https://jaspwr.github.io/spectra/?embedded=true&startPaused=false&project=eJytllGPmzgQx7%2BK5XvZ1ZHUNiaQVH1q1bunu6u2b90q8oFDLIGNjMkmWuW73xjILgk0l62al4QZz8z%2Fx9jjPGMtSolX%2BKvcu8ZK9EmWBgc4N6Ko8erb9wDXW5FJ6x%2Be8UYVsg8ohdLzjRU5rE6NdlI7WIN%2F28FaZTQKCUGyftSPurIyVa1tq%2FJthTaFEe699zRabYwtUS3KqpCWfUJO7sGjNNrJlKFm99EYm9VgMo3zNo4%2BQ8mPpjC2zbAzKkNeyt09en7UCD59JPowDPeOZjc%2FgJXOCZq1D739JSM4Xfca7uA7gDX3sOSIj8GYHDDd%2F5J3HBxVplYOXK8cZ2xDDP%2FrBeW0BoTdnXLM9wf0u4e4f8fmpEfIi%2FU%2FvR%2FWDsodHzU%2BQhMrVclCafmHFdUWr56xNpnseqoyEE%2FmPFoSBtJJvKBxsqAR0LlD5YHzYlZZk1tRgu2U3CfZ4xUjJMAHvKIROQY4E054RyH%2BlcVZJPIF4U1iY1WuIPobmUcBAWmlFDW88szHPanMgTwasgBvJewWh1dJDFG1LGTq%2FKINbEzpO9LrXi4oi0IecxZTnsThq%2BwnpTPzNJYc8hBKt6LjaEJ0F%2FcmwUn8qpeTsV4oApsM0uRjgIREcUxjzmPgWPABQHfyxgAzylv5k%2Bq7oE796fA%2BmMam8jNs4b8ut%2FCNgIwNOhKztxHyJEooB7ZFxMI4Ifx2xOkO3c7YDqifYUyStzHGwBhREi0ppZwxOjg90pTS2cMYktN%2BH7JJylPgibPP95BaKTX60ogMjP0I%2FRuaaVV3pL%2FffMrCV17K6NuAGYuX0TJaLJZhGPGQDeZFr2miq4wuu7ayKeDTdXDO249kb%2Bh%2BPdgUzH6u1CadV%2FrmBtPFoMGMnO9iZ5sJXkgks7yflHW7xX44LTv3n0JnhV%2B0XsOsrxp%2FSzhhc%2Bl%2BOK5a70scUATdS94fZr74ej1R75R9Nk7ZJpgYmAP5EzPnJvWTl8S5%2FP5ivAS4rDjQP0rap7iOMDVUfhVD%2F7dm1ITLktcg%2BhzXISamxq9iGIydS47LqtcwBmmuo0zNg9tYpm6HcxY4%2BBMYo4pDjsukPsXRT8ZSpNZ0Y%2FI%2Fg6diHA%3D%3D" style="border: none; display: block" style="border: none; display: block"></iframe>


<h3> Vertex Shaders </h3>
<p>
This section is a little more advanced and it's ok if you don't fully understand it yet. It's not necessary that you know how to write your own vertex shaders for most applications.

Before a fragment shader can be run, a vertex shader must be run to determine the position of the vertices in screen space. For all of the previous examples, we where drawing to a quad (two triangle that form a square). Each invocation of the vertex shader is responsible for determining the position of a single vertex. In some situations you may want to offset these positions for effects such as swaying grass or wavy water.
</p>
<img src="https://learnopengl.com/img/getting-started/pipeline.png" alt="Rendering Pipeline" style="width: 400px;">
<br>
From <a href="https://learnopengl.com/Getting-started/OpenGL">learnopengl.com</a>.

<p>
We can also pass data from the vertex shader to the fragment shader. We can do this by defining an <code>out</code> variable in the vertex shader and an <code>in</code> variable in the fragment shader with the same name and type. This value will be be interpolated for each fragment between the vertices. This was how we passed the UV coordinates to the fragment shader in the earlier example.
</p>
<img src="https://i.sstatic.net/M0Yqe.png" alt="Interpolation" style="width: 400px;">

<p>
Now let's try some 3D projection. We will brush over the maths here but you can read more about it <a href="https://learnopengl.com/Getting-started/Coordinate-Systems">here</a>. 
</p>

<iframe height="350" width="800" style="border:none; display: block;" src="https://jaspwr.github.io/spectra/?startIdle=false&project=eJy9l91v2zYQwP8VQntJBsfV94eDvKxDt5e1BbIO3ZoiYCRaZiGJAkXZSYP87zt%252ByJJlxbG7YHmILfJ4d7873p38aFW4JNbCul7hmjTWzMoZLhpr8eWx2%252FmVLpdtQ1BB85WgVQ4yGatgZwmC5Gm2FbyuSdoWmKMVSCrp5lnZ94yXuEAlrutDKt%252BxA%252BZWOGOb5038UjBWjna%252FzqwGjhGuCZe0IEa6xLSaLzmW9lJWCVKB9wvrpzXIUlYhz7YRaW6qm6rmJKVqTXLWaFkwLC7lDq3QmqQeWmu6y27FRetPayXBWiEXfPQOLL1lBeNqec1ohqQHZ%252Bfo8aZC8LcVQFfqxJnUfGbPo%252FMZcubncOzJkrBjBPBXvIjw5g36c0VQzRoqYGeGKp0OXGXo018oI0takQyB9wLESpaRoqfrTl32S9WYt9W4bUWXsAVowtdqLkeLa0o247Was28kNSY6Z%252BECrnHRkgZhTlADbEgw5Z5MWimfdWYVBAV6XrMCC8CAGBKcrraCSuUdERtCKr0jg0but%252BkZZtAs9SmcyBWouyZgVXoD4VtyVvaBe8ZNfRKUQn5VtMaKTEqOUobwEniR4LiSYYSKQlRsVW6oWA1UQIw5vTf2TR1eoTO9%252BbO%252BbNr4DNnz8%252FP5%252FcP33r%252B3rJLRQqzl25sgvVqxkuUEwtWglDGe0Qpi36hkSLcalV4qFM9WWcFSMN7UOCVSx4bxIjOPh5yWBQS2wesdp%252FvrrAvEGPmor5PyGO41GNz6rYI7tApOpAWt9ZPWkBe3Hzv5q8HdlFbh8sIHqNPlCN2lpjUpoHh%252B47heWQtoRuChbjY0g2K0504cuFES%252BV4Y2lESuwFUq3ioZQHnxQXozzmWbatzUiq5txZe4sysB2vh2PYT9DQssNwo8B0pdk4iaRA6g8U4zSmc%252FmLPg5kNrpUENy0nmTy3oZkA9xzPnVkrIlu1tYgjONWQAvCkkGqYYAluWi5bdN9fDYgdxmHoBoHnx66XxH7Ug2xoBa15HyJIPHBGYbjBBIY%252BdxJCHPUEvnMaQWRLgtj1wRuIb9ID6LLaB3BCnYVoyntTi8r7bs5cw61LyTto0u%252FHc%252BZIQNcd5ChyTyN0bMf2Q9cOfC%252BKI8jY8YgX%252F5FRDaIfYXTcE9Now4kgiOAO2okfuLE3uIk5YSUR%252FGGKU99Ed7qgzLmO1Kj7Q%252FYbeDTz6gNAcqoLXJLJ3WuegqAguGZizu6%252BHR0Dzx7EIDgxBonreZ5rJxAL2%252FF8v3fZuLofgIvE14l2J2uxG8m7AVC9HMaqVHNskwmHyQ3j08BCP%252FQDL47iOI7CYYm%252ByOUFU4mdxurbOqwt2Rp6CdyOimBuLaCKYE1%252B0733f2CO%252FCSIIhsy6sOsiE9K5vG5lOMLnuC0rc7C%252F%252B%252BgIQBNAvOciM9qTX%252F%252Fe%252FD9H%252FW9rT%252BbT9hz5Kdc%252F5EAeX6yEyDB24n4gCKS5WaYNqrnPDtQ9fbv8PZRSKHbW3iNq1v5YqwJnh9gant7kMr7oLJy%252F3Ahrd%252FeThjs1F9M6FQaRrmXqR4ATIyho%252FyffJPY9d%252F8oBkTjC0OAPaUGhWHEabmzGsxmF80e1kYmzwEYXQchpicI69FMRhEY5J9u4dQBooO40yMhONgpt4ZdmFKMwbHJGOTQ46x1k7HYYj99v9aDDstfwwyMnuIY0fPCzD7ff21aEwv3%252BMYWTwEYlSMEb5Cay5xypl6yXn6FzKlslE%253D&embedded=true&startPaused=true&defaultSourceFile=main.vert"></iframe>

<h3> Frame Buffers </h3>
We may want to run a fragment shader on our entire scene for post processing effects. This is one of the many situations where we want to renderer the scene to a texture instead of the screen so that we can then use that texture as the input to the fragment shader. This texture is known as a frame buffer. The way you create and set a frame buffer will depend on the OpenGL implementation.


<h3> Depth Mapping </h3>
A built-in feature of OpenGL is the ability to create a depth map. This is a frame buffer texture that stores the distance of each fragment from the camera. How you create a depth texture will depend on the OpenGL implementation you are using but in general you just use the same vertex shader as before to render the geometry and OpenGL will handle the rest. This is useful for effects like fog, depth of field or shadows which we will look at later.

<h2> Rending Techniques </h2>
Now that we have the basics down, let's look at some fundamental rendering techniques. Most of these are real-time "physical based rendering" techniques meaning that they aim to represent real light interactions as closely as possible while still being cheap enough to rendering in real-time. This section will assume some knowledge of vectors.
<h3> Diffuse Lighting </h3>
Diffuse lighting refers to light that has been scattered around the environment. This light will generally be quite soft and does not include hard shadows (we will look at that later). 
To calculate how bright a fragment should be, we can use the angle between the <a href="https://en.wikipedia.org/wiki/Normal_(geometry)">surface normal</a> and the direction of the light (e.g. if a surface is facing towards the light source it will be brighter). The surface normals will normally be included in the model and passed through from the vertex shader meaning that they will be nicely interpolated. Our intensity can be found using the dot product of the two vectors provided that they are noramalised.
\[
\cos(\theta) = \frac{\vec{N} \cdot \vec{L}}{||\vec{N}|| \cdot ||\vec{L}||}
\]
\[
\implies \cos(\theta) = \text{norm}(\vec{N}) \cdot \text{norm}(\vec{L})
\]
Where \(\vec N\) is the surface normal and \(\vec L\) is the direction of the light. We will then use \((-\cos(\theta))^{\mp}\) as our intensity (in graphics \(n^{\mp}\) generally means <code>clamp(n, 0.0, 1.0)</code>). In practice this works like this:
<iframe height="350" width="800" style="border:none; display: block;" src="https://jaspwr.github.io/spectra/?startIdle=false&project=eJytWFtv2zYU%252FiuE9mIXsqv7xUFftqHbHtYV6AZ0bYqUsSiZrUQJlGzngvz3HV5kyZLi2kMCNBaPyO%252Bc7zsXOn00GC6IsTJ%252BpWm6rYlhGlmJ89pYff5iGvUGJ4SLxaOR0pzovQWmbLkjvIHd65I1hDWwx%252FgJTDUtGXItC5H6ml0zytCOrF1UlTVt4NVVZ2IlL3B%252BMDhou7sSR7aMpvAKFbjxUFEmROw5Mu4o2Q9tFS%252B%252FkbV2cc3KbaO87N61brTJQbt%252Fdt0S0N6XtTyzK2mCBLXZHD1eMwQ%252FsBW9UYHJpQID00wGhl5JiJmiYiJrOZ8v7%252B4f2u2ADHuPtrZCmMhezvW%252BLL95r82wvWMizgBV8aFifDKezHEiUo6zHyai4mRNpW1Ds02F0rzEzVU%252FRZ1SbUKUUGrV0%252Bmg3Ftw%252FEuZl%252Fw5%252BV6%252FRn9vCFrDni1HZYoaWNVbnuI1QXvabKAIUA7xNAgCo42WTUSDi1sKbEAPsZzZQlxH%252FHLn0lsPPqFc63XwwHpIsGpRFgCj%252Fo1AMMtygm5JsyeEtShgTY5iVolWB6WC%252BtwbtM5xUc0WSdnoaqAPZKYlnZuoswHsfC6I9CtAYSWqBX%252FmQhFGalE8Er8f7NeC3n1F%252B5J%252Fr0G67xA5ygmvDqErsesl%252BkPQoDVa4xrEhn2cHEC2NWUZCI4a0B8cacokTUHJVkYdjkoQ7F%252F2RE0pk30AwczaVL0aEzDbPMr0tWwPdaPy4s0kWqsHFDlMnopWJKeM%252FMZxtTFWjwaDLlKDiCZQ4tbSsxzf833L8WI7jkIfWqC5r0RX6MEAhrbbBMCdsXKswDTujZX1ZBoJbrAw5%252FiW5N0hJPx0UF0zgi0td8bK802DEcwBZWmDTTzZlkAsgTYFV5%252BtpW9awKEgGAqHJMLNniYN8LADxzQ2ROgDCz%252BGYzXJwYPYlcLcJRAZyANAmTaIlteU%252FTjy4siPvTjw3Dh2L6Bsh%252F7ZpMXQgRWctpRcpvEgSMIGzDPSfJQm9fxv7%252FmTfN5WH%252FUnvLPF5yel%252BMX6uE5wmT5BGEVx4DueGwaWE8cdJXWRjeXxIi2PP1UT6lSrjlp9gO5ak7cwg98NL8MzOTpOvwYc%252B0KOUeRC0btOGMdWYIUdxyxfQLlmHE%252BUQRjbkqczybM7qbiemyy3RyQKL%252BMhejaADPtOYLlx6PSKOSNlQRp%252BP6bhW56k4VuTNPS5QTn%252FKe5fWOpi%252FwtyxakaJoa8mw1BTzx84GuR9WpDOFmWt9%252FOzqgV9TIaXNjVlh2Goec7tu8GsRPE7lmjzFeF608mdLqvG45ZnWM9zQ6N7b3E7Gr49iRJL%252FAD23O92IncY4rPtSbkWAbpTub6%252FNaUX4%252F%252BT2uGzjiPPUZxIPrPDbzAsfzQ6zXinrKk3I8ZxUEErmUbTk5jde6iFozCLl7POqfuAIckmb5Ka6nYc9epevs7fAnKxZ6bG%252FjmV23Fl34175%252BdufLt4dzRHSrFu7tfiBhubsZuWyeLMfIRzkReemQmLsoXIqPvxiGNocMTNDTCaQITgZxHYOJ2GBBQf7YNCQwd9gkMMDXCaQJT4%252F2FGPSuhyGLkdcTNHowp6lMzuezuEzeccdkCn05DZmMnfaojHBblNNEJmbwC6VE%252Fwk6au6BwxPZ0Ag%252F6IpxIGcRmBrVxwTo1GwauuuFP0SkUzPpC8zjAq95Kf835ek%252FzD9j3g%253D%253D&embedded=true&startPaused=true&defaultSourceFile=main.frag"></iframe>



<h3> Specular Highlights </h3>
<p>
Most surfaces will have some bright spots where light is reflected directly into the camera. This is known as a specular highlight. Whether or not a surface has a highlight is determined by the angle between the reflected light and the direction of the camera. 
</p>

<img src="https://upload.wikimedia.org/wikipedia/commons/3/35/Phong_Vectors.svg" alt="Phong Vectors" style="width: 400px;">
<br>
From <a href="https://en.wikipedia.org/wiki/Phong_reflection_model">Wikipedia</a>.

<p>
The angle at which light is directly reflected off a surface can be found using the formula:
\[
\vec{R} = 2(\vec{N} \cdot \vec{L})\vec{N} - \vec{L}
\]
where \(\vec{R}\) is the reflection of \(\vec{L}\) about the normal \(\vec{N}\). Next we need our view vector \(\vec{V}\) which is the direction from the fragment to the camera. We can find this by finding the difference between the camera position and the fragment position. We can send our position through from the vertex shader. The angle between \(\vec{R}\) and \(\vec{V}\) can be found using the dot product as we did for the diffuse lighting. Finally, we can raise this to a power to control the size of the highlight. Since we are using values from <code>0.0</code> to <code>1.0</code>, raising it to a power has the effect of lowering values the closer they are to <code>0.0</code> and gives us a smaller highlight. All together this looks like:
</p>
<iframe height="350" width="800" style="border:none; display: block;" src="https://jaspwr.github.io/spectra/?startIdle=false&project=eJy9WFtv2zYU%252FiuE9mJ3sqv7xUEfuhXZXtYVKwZ0a4qAkWibnSQKlGzHCfLfd3iRJUuKa3fBgjQWjw6%252Fc75zI91Ho8A5MRbGO7pcbipimMaK4awyFp%252B%252FmEa1xinhYvFoLGlGtG6OaTHfEl6DdsKKmhQ16Bg%252FgKiirECuZSFS3RQ3BS3QliQuKllFa3h11YoKxnOcHQQO2myvxJZNQZfwCuW49lDOUiJ0joRbSnZ9WcnZV5JoEzcF29TKyvZ9Y0aLHLT9c9suAe0Dq%252BSeLaMpEtQmU%252FR4UyD4AVX0RjkmlwoMRBPpGHolISaKioms%252BXQ6v98%252FNOqADLpHqk0gTGTPp1pvld1%252B0GJQb5mIPUBVfCgfn4wnc5iIJcerbyai5CShUramq3WJlhnD9VU3RW2kmoSoQKlVJ06HyF2D4Z9ZxrgUjwdQIOP8joJnwE0sJ7YIlCP%252BuFO586BYbYpGaQZa6l%252BrI31GuFhlBNSSDOflZJayWsefPpCJJjE1USsD1OlUmOvGXGGlquh%252F4hCTuiCVSJfEP9h8%252FRopyGyPdgTt2CZLEc1LxmtUr2mFMPwiXYodKgkkiONOWiUr4YP0w5r3qItEv6NcJ%252F5Nx30Rd1FUaNYDbaiAi9e0SHVg2BJxsswUUMdAKxw348yhzkQwdQhNkY2pqD1d9DMpOLIJUmX0jtQ7QgrtIAhPeKMiX5Uk2WSYvz3KprTfjYQ55vcgmeDNH5hWBNUMklGyHeHiMcf%252FEETBlkgfiIRbCdsWROSOod2a1kQGp1uC2q8mYwA2OfLVRI4Pbd4tkLdpCrVA2r0ALtZLGaEEOmTDOyaUGOYCvZ80rfFqWIpm0zeyXaYKQPz8eDCk6R%252F6UDntTaSFJkAwNGCSl7QkGS3ILxyXa2PxaBQwldRgpymMDGvuWY7v%252Bb7leLEdR6EPI6Xel2LK6OoGQTO9BMC9sbBd2zT2xmLmW0%252BmkeIaixcZviNZuw0JSy1YO95AtmRbY%252BH5plEQzI2FNQe8pXiyLYHIIBgUjH225r5pAYuc4GrDSSrM7GhaAxM7cExjTUTUYOHHsK0iomKE1hJOMgKeQYAAaKUFYohq0n4ceXHkx14ceG4cu2eQjhRn2%252FHP5ixKGlaw2ZJ74e%252BD4AgKmK9I%252FUmK1PNfnee%252F5fOm%252FKQ%252F4Z0tPoX8e8LjOsFl4QnCKIoD3%252FHcMLCcOG4pqZvBMDpeoMNjjZWE2tVER60%252BQnck5BoOtff928WZHB2nWwKOfSHHKHKh6l0njGMrsMKW4yqbQbWuOB6pgjBWPJ3R0m93Kq7nJsvtEInCy3iIpg0gw74TWG4cOp1aXhGWk5rvhzR8y5M0%252FNF0Nft65fybuNDAUhf775ArTtU0MeRlxxD0xMNHnoisl2vCyZzdfT07o1bUyWhwYVNbdhiGnu%252FYvhvEThC7Z80y3df%252BBbOs5rioMqyH2aGxvf9ldHmBH9ie68VO5B5zfK43IcnSS%252Fc%252F9qa8cH5Pb4bOkGKHURyIBnQDL3AsP%252FQ6nbiD%252Bw3bDRnFQQSmZR%252BGY%252BNY7buoB6Ow9dezzkkJ4JB0pQ%252FTSkbsuQNVvf0VLiKZ0Lm9hbt0uRFfo9TAf3boyreHfUdnqAze%252FX4mfLi9HZptjMyGyEc4I3npkBk5KF%252BIjD4c%252BzT6Bk%252FQ0AinCYw4ch6BkeOhR0B9Ee4T6BvsEuhhaoTTBMbm%252Bwsx6JwPfRYDqydodGBOUxkd0GdxGT3kjsnk%252BnTqMxka7VAZ4DYop4mMzOAXSon%252BUj9o7p7BE9nQCN%252FoiqEjZxEYG9XHBOjYbOqb67jfR6RjM%252BkLzOMcJ5zJ%252F596%252BhcaO9HO&embedded=true&startPaused=true&defaultSourceFile=main.frag"></iframe>

<p>
Having specular highlights can be a very effective way to convey a smooth or reflective material so often you will want to have this controlled either will a parameter or a roughness map which we will look at later.
</p>

<h3> Fresnel Effect </h3>
<p>
A very subtle but in my opinion very important detail to take into account when rendering reflections such a specular highlights is the <a href="https://en.wikipedia.org/wiki/Fresnel_equations">Fresnel Effect</a>.
This describes how the strength of a reflection changes depending on the angle at which the light hits the surface.
</p>
<img src="https://cdn.discordapp.com/attachments/1098152470645055510/1270349544873398342/Fresnel.png?ex=66b360b5&is=66b20f35&hm=3ddc5da76a87787b7b9e25b89e67635b1970c5c831dc562a462e9b1dd34a6df8&" alt="Fresnel Effect" style="width: 300px;">
<p>
In the above photo in CB04, you will notice that the reflections on the ground towards the far end of the hall are far stronger than those near the camera. This is because light that is reflected a grazing angle is reflected far more intensely than light that is reflected at a more direct angle. A simple but effective model for this known as the Schlick Fresnel is:
</p>
\[
F \approx F_0 + (1 - F_0)(1 - (\vec N \cdot \vec V)^{+})^5
\]
<p>
Where \(F_0 \in [0, 1]\) controls the overall intensity of the effect. Also note that \(n^{+}\) means <code>max(n, 0.0)</code>.
We can now multiply our specular intensity by the Fresnel value for more realistic specular highlights.
One other implication of this that we can include in our shader, is that stray light will be reflected more intensely at areas with a higher Fresnel value. We can represent this by adding some white to the area where the Fresnel is higher. This will also highlight edges of objects and give the scene more depth.
</p>
<iframe height="350" width="800" style="border:none; display: block;" src="https://jaspwr.github.io/spectra/?startIdle=false&project=eJy9WFtv2zYU%252FiuE9mK3sqv7xUUfuhXZHrauWDGgW1MEjE3b7CRRoGQ7aZD%252FvsOLLOoS1%252B6KBUEsHpHnnO87N8YPVoFzYi2sN3S93lXEsq0Nw1llLT5%252Bsq1qi1eEi8WDtaYZ0XtzTIv5nvAadi9ZUZOihj3WDyCqKCuQ7ziIVNfFdUELtCdLH5WsojW8etmKCsZznB0FHtrtX4oju4Ku4RXKcR2gnK2I2NMR7ik59GUlZ5%252FJUpu4LtiuVlb2bxszWuSh%252FZ%252F7dgna3rFKntkzukIC2mSKHq4LBD%252BwFb1SjsmlUgaiiXQMPZMqJgqKjZz5dDq%252Fu%252F%252FSbAfNsLeztSHCRu58qvdtspt3WgzbWyTiDEAVH8rHR%252BvRHgZizfHmq4EoOVlSKdvSzbZE64zh%252BqUZopapJiCKKLUyeDoydwWGf2IZ4524Sc2opjl5klVhDue3FNwFwGI5cQV7nvjjT%252BW548ZqVzSbKtAiFE9tNIMDS1apZXtCGcfFJiNwaJnhvJzMVqzWIaJfyETjBB2tDGxMp8K4GRala6Xq4kcOtNUFqUREpf6jzRcvkFKZ3aMDQQe2y1aI5iXjQMOWVgjDL9L0GMCWEEOOjchLjMIH6Ycz7xEhcuEN5To3Xhnui9CIvEOzntIGCrh4RYuVJoatESfrTCkyDLTCcTPeHFJRkKkptEVspiI9dV3MpKBjE6TK6C2pD4QU2kEQnvBGMV%252BVZLnLMH%252Fdiaa0bzJhj%252Fk9CCZ48wemFUE1g2CU7EC4eMzxPwRRsCXCByLh1pLtCyJix9BhS2siyTETUvvVRAyUTTq%252B2sgL50ZSNuzXW4LWnFQFyUycVw5oguTvpN0VyODFczRx58DrlSN4FpbUOsd3Kq%252BPoehwMlW9yEbhvF8bZLUhv4pcpsVG2AC1ztyNTGdfr5SvR6DAhPRdhnMJFb%252FjBh9KDH2O3k2aqn42rBu7KXnhmxNOlQbx87y19Ew65M%252FNl6bHmqNj51ExCCbShybe0CZhdpW0JBktyM8cl1tr8WAV0IfVKKMraJLOPHC8MAhDxwtSN03iEJpofV%252BKvqqLFQRNvxYK7qyF67u2dW8tZqHzaFsrXGPxIsO3JGuPIWGpVdY2dJCt2d5aBKFtFQRzawHUg0w8uY7QyIAuCsY%252BOvPQdgBFTnC142QlzBzoqgYkbuTZ1pYIRmARpnCsIqIAxK41zG4CngFBoGijBWJsaNBhmgRpEqZBGgV%252BmvpngE4UZtcLz8YsshFWcNiRZ%252BHvF4ERNmC%252BIfUHKVLPfxnPf8vnXflBf8I7V3wK%252BbfQ43vRZfREcZKkUegFfhw5Xpq2kNRdaMhOEGl6nLGUUKcadtTqPdTPklzBGH%252Fbv0%252BdidHzzBTw3AsxJokPWe97cZo6kRO3GDfZDLJ1w%252FFIFsSpwumNpn57UmE9N1i%252BASSJL8MhijaCCIde5Php7Bm5vCEsJzW%252FH8IInUDCCEfD1ZzrpfNv4goHS53sv0OsOFXdxJLXO0vAEw%252Fv%252BVJEvdwSTubs9vPZEXUSI6LRhUXtuHEcB6Hnhn6UelHqn9XLdF2HF%252FSymuOiyrBuZsfCDv6X1hVEYeQGfpB6id%252FF%252BFRtQpCll%252F5%252FrE15xf6W2kySIUQDURqJAvSjIPKcMA6MSjzAhYEdhojSKAHTsg7jsXaszl1Ug0nc%252Bhs4l4Uk9oMw9X3PiyDvvOCctPN02vmXpB3c8s9uKWaOxUEHT813I3BAj7hjqLtBJRPgqfuBevsLXBMzsefmBv4ZKnfi%252F2A1v56cIfLt8VznSiCpvLufCR9uboZmGyOzoeaOnpE0M8CMzP3vBEbP%252Bj6MvsETMLSG0wBGHDkPwMi06wFQ32T0AfQNmgB6OrWG0wDGxtV3QmCMuz6KgdUTMAw1p6GMzpuzsIzO7C6YXA%252FbPpKhUQPKQG%252Bj5TSQkZHynUKiv5UZFHfP4IloaA1fqYqhI2cBGJs8XQB0rDf1zRnu9zXSr%252FekkelxlvNjF4Gu83JgDN3vGzTc7%252BvUGvoAPsE8yfGSM%252FkN6eO%252FGN6QLQ%253D%253D&embedded=true&startPaused=false&defaultSourceFile=main.frag"></iframe>
<p>
We will not cover any other types of reflections in this post but if you were do add some other reflections such as skybox reflections or screen space reflections, you would also want to multiply them by the Fresnel value.
</p>
<h3> Normal and Roughness Mapping </h3>
<p>
A technique that we can use to make flat surfaces appear more detailed is normal mapping. This involves using a texture to store the normals of the surface at each point with the red, green and blue channels corresponding to the x, y and z of the normal vector. These normals are then be scaled with <code>normal * 2. + 1.</code> and added to the normal before calculating the diffuse and specular lighting to give the surface more detail without adding more geometry and hurting performance. 
</p>
<p>
Similarly, we can use a roughness map to determine which parts of the surface should me more or less reflective. A roughness map will generally just be brighter where the surface should be more reflective so we can just take the <code>r</code> channel and then multiply the specular intensity by this value. There are several other things that you may want to control with this texture such as reflections but we will not look at those here.
</p>
<iframe height="350" width="800" style="border:none; display: block;" src="https://jaspwr.github.io/spectra/?startIdle=false&project=eJy9WVlv20YQ%252FisL9kVKKGa5PJa0kYe2SduHNg0QFEgbBwZNrSSmFEksKfmC%252F3tnD4qHaJlyFRuwxb2%252BmW%252BuHcr3RhatmXFmvEsWi03JDNNY5lFaGmdfvppGuYrmjIvBvbFIUqb3rqMks7aMV7A7zrOKZRXsMX6AqTLJM%252BRgjFh5kV1kSYa2LHZQkZdJBUvnzVSW83WU7iYI2mzPxZFNlixgCa2jykXrfM7Ens7kNmHX%252FbmC599YrEVcZPmmUlK2H2oxeoqg7V%252FbZghoH%252FNSntnmyRwJapMpur%252FIEPzAVvRWKSaHCgymJlIx9EpCTBQVE2FrOrVubu%252Fq7YAMeztba0OYyLamet8yvfyop2F7w0ScAariQ%252Bn4YDyY%252B45Y8Gj5pCMKzuJEzq2S5apAizSPqvO2ixpL1Q5RhlKjlp12lvsFBP%252Bcpznv%252BK2M1kXKOHmHyg1fRDE7H1rL1lExuFAWLG4tSD1RlazZYz568wZ9kqdRtWKI55vlKmNlqRbV8d0kmLdiN9WGs4mQYwqKU4uf95GibI6i%252BVwiAtUq52jB87UcK2eDEoWl3dxEM%252BDXMfJ6J0lQ1ZJUbLSOReurBJzW1ksZrVZtedU9UG5EjIjHSQlWEIaZmmhmWyaK81KNp7sjin6ULYHTWxSnwG4ym%252BeVjtjkjuknwGimQMZ0KqK5HaQKaq6qxE8cgqjSFpXwXS1jCE8etYJaKjwLANGF38CadveLMH%252BXcB32b1u6iKgTZkOzHmitlzzP2SJVh4dRiAVJ1PA2hRmnMKW9NpPjDlERHps04j92bCcgOrqaQ6L3bCcCK450hNbI6OoW2SC6F7HKy%252FUebbkiv550NDIREcUGKExsqw3S9%252F3ivSgpcFxuG9B%252F53%252Bv5%252BoFZ2XGREgDxmtg5O%252BkLd73xbD5kv0uYiLJljtrqb0a5g2yPWtnGIDClu11o2CRZDKF1snNZKIzQ%252BzcCzqzzhuBZ0%252BRwhA%252FrxvTvdqJFrKw29nV1lez3lUzZXR3ItWp3QilF%252B7DIilYmmTsVx4VK%252BPs3sigtqvrMZlD4cWWi4nneh4mbmiHAfWgMFe3hajVuqLBRH0HCIAb48w3jVvjbEa9B9OYR1UkptPoiqXNISTkNFDNFQFzi3xrnLmeaWQs4sYZGATmxJONMSDmYLUERH3Blmdi4LBmEdQYNhdirpN5BTxsn5jGigl7wMAL4VjJRFSLXQvoBhhoBuYBoKWeEBeRpuyFgRsGXuiGvuuEoTOC8ix0JWnHw6NJi7iFkTgdyMMAcWecwXMV8SWrPgP3%252Bvnv1vM%252F8nlTfNafsGaLTzH%252FHPs4xD%252FOPj4NgtD3iOtQH5MwbCip9mrfPK5vS4bKg33zqFO1ddToU77hMfsFOoMP%252FRZtJEdC2jFA7CM5BgH4kjiEhiH2MW04LtMZhOuSRwNhQEPFkwyGQXNScR3rLKdFJKDH8RA564OHPeJjJ6SkFcxLlq9ZxW8H3EVDSYMO09DneuH8h%252BgKYaiD%252FU%252FwFU9UMTFkx2gIeuLhE49hf7y5YlZ%252B9W20P3HQ8qd%252FZE5jm1LqesT2HD8kfuiMKWTEUe6kR5SyikdZmUa6lt3KHL2TGQqA9ovUL9f3fNt13JAETpfpY%252FnpYazK1%252F%252FMT9m5Pys%252FnYG4blEKfZGFju%252F6BHvUbaXjdZLN8%252Bt9SqEfgGyZjIPeU%252BeOSsSANgq7%252BDifEKiZHqUk8EM3cD3sjgg%252FG6ub1CZHhJ%252FqusWEelLJxvP4X%252BtbMdo5nQAkmBxbdEKfUNunjuvZNmTeEWSd05C9zF6OLqYk9GlIvQCHGPvUHlNaAlVa3GNKC7wLPYsRdY8jRF2XEooDH%252F46Ph7Dp3afd0QDdMh95cu5zyc%252BZBi0ewGErR%252Fax9yQ4fe8IctixfgL3pE%252B2IA41KYBtR1nXBhrt4fPviFF%252B2vLK3L2PW9HQBKvSOrVppSX12OvN2r1tyibp2LP5WW%252BqYqN%252BGpQ9d%252BP9sBydXeu804jLXxzOxM6XF7ui62FzPaROzgDN2SLzMCLy4nI6HeVPo2%252BwAM0NMJhAgOKjCMw0K33CKgvd%252FsE%252BgLbBHqYGuEwgaF2%252B0QMWsWoz2JP6gEaLZjDVAY75lFcBt85umTWuhT2mewLbVHZw61RDhMZaIdP5BL9RfVecvcEHvCGRngiK%252FYVGUVgqGnuEkiGalNfXEv9PmLydE0aanxHaT%252F0FtPVXn%252BzPEBhT2iLQx%252B3QXkqtfeb2hMREV%252BoD6Z1T%252BIBFhriiZQeaFRPREH2pgP53Jd4gIKGOExhoDU9VTQVLB5g0Bd4KJIUwhPJvN9tfv8Loi%252F0FPfDQLc4jshAuz3ucuhLbLPogT52M3yFXnEdxTyX%252Fw9%252B%252BA%252BWuUqj&embedded=true&startPaused=false&defaultSourceFile=main.frag&scene=eJy9WVlv20YQ%252FisL9kVKKHa5PJaUkYe2gduHNg0QFEgbBwZNrWSmvEBSsmXD%252F72zB83TMuUqNmCLO7tzfHPtUL7X0iBh2lJ7H63X25JpurbJgrjUll%252B%252B6lp5HaxYwRf32jqKmTqbBFFq7FhRwekwSyuWVnBG%252BwFIZZSlyMIYsfIivUijFO1YaKE8K6MKts4aUpoVSRA%252FEgja7s44yzaN1rCFkqCyUZKtGD%252FTIe4idtOn5UX2jYVKxUWabSupZfehVqNIBO3%252B2jVLkPYxKwXPLotWiEObzdH9RYrgB46id9IwsZTCgDQThqE3QsRMQtERNuZz43Z%252FVx8HyXC2c7R2hI5MY67ObeLLj4oMxxsknAeg8g9p44P2oA8DsS6CzbOByAsWRoJ2HW2uc7SOs6A6a4eo8VQdEOkouWr56dFz56D4lyzOik7cyiDJY1aQ96jcFusgZGdje2kS5KMbZc7C1oawE1VRwp6K0Y8%252Fok%252BCG1XXDBXZdnOdsrKUm5L9kQjurdhttS3YjOvROcS5Uag4qKg1yQnHG690dQXpCgWrldAJHFVWoHWRJWKtmAGhIdkU4W2jncNX2iFfIMLEQAtIibMOwzv1EN0xlWNz4YVHM4PkKoKYt2FJn9fINlddhnLLU4w%252FzkpwIvfrXEcL09BRmJVy3eiQ3gvSDQB%252Bh8IYoM8Wq6yaDczSW5aCjvmcF0M7x6WolWwyPxeQg5UKiBDftTKE7C6CVk0IgxceSLTh1zN6buBV8j4qVNW0vcaTVnh40RNa2yX4C7aOJfO4FAjOG9Tg1rkb50BSYVqIdQcoz65tHBQ%252FdXzHRXRs1cdUD3zHsy4MVILXktHVHpmgupfwMsr1GeW5PLuZdSzSEeG9CiDMTKMtpB%252F7cwwysGF2wJ0DDTbeKuZzzAVxHXKdBLftLNG74ZnLNskj2VfGVhv2O8%252BMKN3wHnv%252BKJwY3YCvo1SURxLdzmaqCPi5QX7pdYlwreZclTj%252Fedt46Q0gesM90t5tG6PQP%252FY76Vd7JsyoIwXNGW7MPMpZHKXs1yLIr7XlvZZC95cXaLSC1owNGxPHdhxMbN%252F0PepA6672Oe%252FmqucBob4luIBbbenq2l5bLqjzoGuroAo4OQ6uWNwwIa6nEdVcIkBbZzttaTu6lrKg0JbgCKDxJxNjkJiBtyJQ9QUbjo4BQ8ICaCNsxdXcRKsKcJgu8Fwz7g%252B%252B4Gwl44nLT61hXmBgGbgHBG0UgV9VCrLje7bvOb7tu7bl%252B9YEyAvfFqAtB08GzfMMVpzbE8wg4k5bwnMVFBtWfQbs9fPfred%252FxPM2%252F6w%252BYc%252Fkn5z%252BEv9Ylnmcf1zqeb7rENuiLia%252B30CSA9jQPTbXt68j2HeP5Kq9I1efsm0RsnOYHT70h7iJGAlp5wA5Mgdcz4NYEotQ38cupg3GTbyAdN0UwUgaUF%252FiJKNp0HBKrFODZbWAeO5xOHjNuhaBaLnY8ilpJfOGZQmriv1IuKgvYNBxGIqvl85%252F8LkRlirZ%252F4RYFZFsJpqYKTUOjz98KkI4H26vmJFdfZscT0xb8aRHxhOblFLbIaZjuT5xfWtKIyOWDCc9opVVRZCWcaB62V7U6J2oUBBovkr%252Fsl3HNW3L9olndZE%252BVZ8OxrJ9%252Fc%252F6FLP9i%252BrTokOMLUi%252By6vQcm2XYIfarXK8idJVdjOE5Lse6BbFOBo9yXdUIXpuY7B9ZEwI9EyHUuK5vu3ZDrYnpJ%252BJ5U1qkiPSTw7WnCCfZLEVWfiv8S2fHJxOAhJ85AVh%252Br5LqOlSy3ZMEyrvCLDWacBepq8HF1Piu9Snjod9jF1qTmktnmwt9jGtBV53XoSIWscBorZNCcWeC38tF0%252FBU4fPOWIAOhS%252B8vXC5xIXKgzGPQ%252FS1vXNY25I%252F3vekGV%252BzYpXvCNd8AGxqEk9alrWtDRWYfdffEPy8dcUV%252BTie96OIIm%252FIslXm1JcXk%252B93sjd34J0FfMzl5fZtsq3%252FMtDOX8%252FOQOL3Ue%252BzjuN8PDtfsFtuLwcqq2VLIaSO3JGbsgWmJEXlxOBUe8qfRh9hQdgKAmHAYwYMg3AyLTeAyC%252F%252Fu0D6CtsA%252BjJVBIOAxgbt0%252BEoNWM%252BigGWg%252FAaIk5DGV0Yp6EZfSdowsmUa2wj2SotAVlILeWchjIyDh8opCor7IHxd1TeCAaSsIzVTE0ZBKAsaG5CyAa6019dS3z%252BxKj53vS2OA7yfqxt5iu9erL4xEIA6UtDH25jZTnSns41J4ICP96fbSsexoPoFAininpkUH1RBDEbDpSz32NByAoEYchjIymp8qmnIUjCPoKD2WSlPBMMQ%252Bnze9%252FQfSVnuJ%252BGJkWpwEZGbenXQ59jW0UPaFP3QxfYVZMgrDIxH%252BMH%252F4DC%252BxR3w%253D%253D"></iframe>

<h3> Shadows </h3>
<p>
The method of creating shadows that we will be looking at is known as shadow mapping. This involves rendering a depth map from the perspective of the light source and then comparing the distance in the texture with the distance to the camera of each fragment. If the distance to the camera is greater than the distance in the texture, then the fragment is in shadow. 
</p>
<img src="https://learnopengl.com/img/advanced-lighting/shadow_mapping_theory.png" alt="Depth Map" style="width: 600px">
<br>
From <a href="https://learnopengl.com/Advanced-Lighting/Shadows/Shadow-Mapping">learnopengl.com</a>.

<p>Finding the position of the fragment in the light's screen space involves another projection in the vertex shader with the light camera's view and projection matrices and then passing the separate coordinates to the fragment shader. We can then use this coordinate to sample the depth map and compare the distances. We will also need to use a bias to the distance comparison to prevent shadow acne (ugly line artifacts).
</p>

<p>
Finally, let's soften these shadows a little. There are many methods of doing this with varying levels of realism and performance but one of the simplest is to take samples from a small area around the point we were previously sampling the depth map from and averaging them. This is known as percentage-closer filtering and is not physical based (meaning it is not realistic) however it's the sort of thing you don't notice unless you're looking for it.</p>

<iframe height="350" width="800" style="border:none; display: block;" src="https://jaspwr.github.io/spectra/?startIdle=false&project=eJzNWutz27gR%252F1c4vA%252BVHEkBQYAPuW4nzePuQ5LL1L1c20vGQ0uQzDuK1JCULTnj%252F70LgA%252BQhGzScXL1%252BCGSwO7%252B9r2gv5hxsGHm3HwVrla7jJkTc50EUWbOf%252Fs8MbOrYMlSfvHFXIURK9ZugjCeXbM0h9WLJM5ZnMMa8we4lYVJbNgIGSz7FH%252BKw9i4Zgvb2CZZmMOj0%252FpWnKSbIKpuYGN3fcq37OJwBY%252BMTZATY5MsGV%252FTuHkdspv2vW2a%252FM4WBYvWsyhcX%252BUfNZvEgw%252FNnckul%252FJdvy8FLG5h4%252FqX6%252FoS5PiQZI3rt5zeLxLGdRIuDa6o0dj48ik24Au2G2cSpriUDODWSMA0TgSZkVTMxECz8Xi2P9yWy4EbrG0sLdU6MazZuFxXSAFrW%252FhgV6UKTkGKz%252Feso4sPBSnYtlV3XDcW35l3k64rrNJg%252FaArbFO2CMW9KxBia6yiJMhPVSepNV66hFS4vKr0XV2q6q6M8AZkeZlESdrwgyzYbCOW4lcGd%252Bnk5l2wVZxBiGLk4YaJTfJSLqyt9%252Fy58a8rViqHLY1FkqTLMA5ylhm7LIzXRg7PhYaNLNmlC2YsQElp8JesoqCoNoiXUrngimm4n3HqGTOCVOUBWDlRHmtsb8hwnBV2FnEFK19yObhrlArhTmM8ry9vTiv%252BL5OY0zLyxMgWKWOxkW2DBZPPG8SUixNwRWo847%252BFfgpab5NkC%252BImOwDChQTJA4EqABbBmgkmyQpcQjyW%252BixU8cOSrcKYGec%252FvXj1868X7158uDh%252F8e7D29fnhitXqEYAcdDsVL2fJ3kQ%252FcqErtWHSWqMwjg39nB32iV%252BCg%252F%252BqmEK9589qyzdoHQ4RulwhNKhRakWOsVAS3wc7UGpe1DpAf4eyshtrv5nvVqjpRMN73FlnfKLWxyskoNxjEWYLiJmXEa71PiDpTGLmmvDlTECCf8GjMcGD%252BUw3jEdxXV4DW7Ossy4kQYAO28ScNtlmOUBqIyngw1PBDpYfFFlOGtmTAXX55xrh5ncsdilKVB7xbb5VcMxZ7ctxYmckaxWGePE%252BdVoPwH9Cg9GyNKhOReZAWRONsJNl4LNJtgqMa2Nea2oUZKxrBIVYjbfpWxU5ZyJKv3%252BAA4gpR3P0haUyySJIPrPS%252F9vKGEq4CACxlI5duAV0fPsjLtyQervsJcYc1A94nqpzXFqNDerIQYUlIX1ujv5sfhTsHt%252Bpu6thEoZ6CIuFvFScqxK1s0BN2JVE6pnweYyBFVIC9sjBJUS6t9YXZLt4vLx1JoY8qf2L2msIF6D4UG1EbjAaLpM8qL0hres%252BDSeGPUtIDoe87KsVtvSqUXz9I%252BUI455aJxJ8hVLIZYsB0qllRJ6QJHAjzcbN9fz8vAqTIuCcabIwkuhSPPTFtGGGlK2iuRmPRU84x5Q4Z5wvXGnKLQ%252FFdcNoNmWLXZRkL5o6I6TaMg60bHu6E6aqqBYamMLNbfBZWJg3gm1jLd6zVMBrBUpRCNAZUDastUqZRkkP55cX4ui5gBiSWb1us2GLddMlFGeCkq4Yi3nXZDimOgYcphFZxVGkXMs2jQo1Dzh1ZtwPyrd%252BKTrPZPSxzk1Mq7j7VmtrpMKiEhuRF2kSl0DErxPzqrGpgx4%252Bbvqm6QhyEisL83V6fvYZpsfvrbxO9K0aZJCR7ojYklsvOX9%252F55P9HmP9G7yhzTsMMdtwy2LoN%252F6MQ22V%252Bb8ixkDAznWhUvQDHgZwpRQijDxLd9zKWguP2y5SgsYcKMUhBPYm3NnYh7M%252BdSldxNzGeQBvx0FlyyqNxmcT02qlhPurZJrc07oxIxZkJpzCBa4xz9ZCAHFBKIhBFa%252FQdc5QYBhw4IMiumSs7kJlzngsBw8Ma9EmYEL6sO2jEWiUpvzFUyxDCQDzwFC6%252BIG95cCMvU94nvUJ75DbN%252B3e0Ce%252BkSAtinqDZrbA674bk9sBhK35hyA50G6Zvm%252F4YFVXvwHcJSf%252FwsP0MydmLstrEH8r3y828KjR%252BnIxs4wHTmu5%252FkOxcR2HYR9v4YlZ5GuilzLEii1GpKbSgXJq3MxKr2BGH7fPl3oCRHjhhuQgRA9D8yJbez6PnKQW0NcR1Pw2HUaaDzBsonEiZEOaL1Vgu1rLFtB4rnDgBCHOhaxiY892%252FFt%252BrCtPE%252FGMMa6GO5vLFEGHmUsRIdh9B1uI9shDkbUJYqxbsIYMr%252FGUJTYIM1xmHLjIDN5bg2BoGEIkIt9x%252FVd6iEfIce1eqQd7ElfIwNyLT%252FN6O12ao5wB8YPZAbsUoItgnyMHAXPJlikSRcNsVyBxtGiEZtKLGVVX7B4QAwRxcEse2BRgApIbLALZDyPIqePdVBRCQcUhTwN4iwKilK4f2Q6H1zyYANgwjalUAk8ir1%252Byc4vcp3eYn9GroMWhRCXUMdzLNvCitNBLtqwy91qpUt44A5ekQwcbd5WdleJbxFE7E2wyJNUVF%252FoumF2escfzs330LvA%252BA3LwkzM4DDkm%252FM83bG%252BWsCumg4H2pMQy7ORZ1tAxnM9THrU5yLn6%252FH3yvlK7%252F%252BYpO%252FigU7rWIDMppgiAlDVCn0UpCMd1tU6bC%252BQ7UniUeUNW0PtCQgJtj3fQjZ0GH16UkylQaFtHtyU3teDi7RElI6VKB0rUhpWpDSs6Ft2qzys7tUeJDaPd3EQDsi3LTJAe94A5XXHGNf63mMMUOJTvpzh5NuGY3OcfPpTEC8jvubiAsbu7Y7nLGm2o42%252BeFrta6AWGt8fplyGi4su25LJtEu5QaeFkxtTAaOZ0J4ITOH%252FbRhthvfAKCjcD0AjSD8AmpmkBUCebrQBtBmqAFo0Cwr3A9DMFE8EoDg66jhSi%252BE9AAoKD1igK0gvALpBowkg1MVBm50ifpti%252BLD%252F62aFXtLrRsGm9GI86Mrf4agAaBMtSNwPQTcdDHGTNUs2LE8PGlnbpDUuoux%252BINN02%252F4nyjTiKE%252BXaloc70k1JYmv0bS28%252F8aVXcI9ta1TpR%252BMalp%252BnvEZIefGpQtkj2CUtdz9xK%252FhwmOJcU2SwVBh2qvtKjrqZ8KxJHS1GF5H4h%252BxUnTLfcDoZsoejUIHZYqiDbVXi2CxqlbGJLh2b164ayB0GaYaJO7SuEBK2i67qeywv09Z5vxfbYY0HU%252BGtDDxaD1D1kDQbXpd6l9o3jpCezj8JjRQvqoj5vPMBeJ00E59DTOBoFrDBTf8rmt%252BN%252FF9dF3XS7MKlDLKHRhPrKpcnhUgS8GwbvOvGhjWk7bd%252FphjqJ6mKMDD4cpdhH4LSaIYGo5ykmHgJfVkjXxfrnrSjqlXBJ%252BLmnRY7Kqg6cz8FjGo%252BCoHnUhjfi%252Bpw7bSifQPn9DpBBJf5JYbGzN2%252B%252BK%252FqeYxn%252BG4pCG0qZFe8Xnav7hPF3A%252BsXuks2Sy997n9kgT5m%252FnYFncNiBaLWRS20PIc937SGK0L47ehotZNsrln5PPVDiYhtRhzuFa%252BMhavim7rBJ4j%252FY4fspAmooVFPkOha1EVaPK4%252B%252FVwYm9wVGn5cIB3Hqdgs08Hd8o0Ahi%252Fq2DTOjT22ouUPAPvZ1CX%252BVJ1%252Bo2xKw9V2gug7xeJFyiA31CvlDoD7erNyS%252FJXFrThM5aRm5E84V9REd6%252FWQVdre8xsMGZi34N5E1wL%252BiCitEE9RjRdSv6W0rogrmVj20bIIpbvDRJWU0e%252FpawWNP4uwtiFzOR5wHeQsJrc1ktYXbPQ75zEsymh0CJaDnxqzO68Q4J2DFl8bITpkfQ7J9FkrF4QtHW%252BHwYM7bxLLEpAY2AtT%252B2AbdcnHgI5kEct3%252BoJQpOL%252BoHQFOmeGERAuhZ1YUJErgrBtyFAYaAE7%252Fdcx6fHIHy%252Bg%252B%252F%252FAeTsAeI%253D&embedded=true&startPaused=true&defaultSourceFile=main.frag"></iframe>
<p>One drawback of our pseudo-soft shadows is that we blur by the same amount at every distance. One solution to this is known as percentage closer soft shadows and involves using the distances of the occluder and receiver to the light to determine how much to blur however we will not look at this in this post.</p>

<h3> Bloom </h3>
Now let's try some post processing. Bloom is an effect that simluates an over exposed camera image where bright parts of the image bleed into the others. While occasionally overused, when used correctly it can be a very useful tool to convey emissive objects or bright lights.

The basic essence of a bloom is blurring (averaging pixels with their neighbours) the bright parts of the image and then adding the blurred image back onto the original. However, in practice, this alone will not give a very good result and we will need to do a series of downscalings and upscalings of the blurred layers to get something that looks appealing. In this example, the bloom layer has been downscaled 3 times while further blurring the previous layer each time. Each layer has then been upscaled and added to the original image.

<iframe height="350" width="800" style="border:none; display: block;" src="https://jaspwr.github.io/spectra/?startIdle=false&project=eJzVXHtz2zYS%252Fyoc9R%252FbkRQ8SdC53E3apNebS9JcPW3v2mYytE3Z7MmkhqRsKxl%252F91uAD4EgJIGyneTaaSKSwGJ%252F%252BwaW7KdRGl3Fo%252BPRy2Q2WxbxaDy6yKJ5MTr%252B%252Ff14VFxG53EuLz6NZsk8rsdeRUk6vY7zEkafZWkZpyWMGX0Dt4okSz2KkBcXf6R%252FpEnqXcdn1FtkRVLCo2frW2mWX0Xz9gbxltfP5JRlmszgkXcVlcy7ys5jOaZz8zqJb8x7izz7Mz6rlzCezZOLy%252FIXyyT14F13ZrYsK%252F6u3zYM1reId%252F3z9foS%252BHiXFZ3r15LezxWM6yw596SgDg69T3%252BkHvwD073nFUx1WS0Atw4UTO9IkTmoBDP20PTwcHq7%252BtgMh9VgbGdoI9axh6eHzbiaCxhr4INZrSgkhYp9Oedi%252FuFdTQqmLfQZ153Bd6O7cd8UZnl0sdMUFnl8lqh7l8DEwpvNs6h8phvJWuKNSVQCr65aebeXurhbJXwPvHyXzbO8YwdFdLWYxzl56UmTzm7eRAvNGBQrXplcxWpSdVkN1LSn7BhE812W5edSFQ0DUkne0%252FXlTS3VzmDt4ghUy70n8k%252B1nhz7zXk8S9LYO%252Fnhxcsff%252F3w5sW7Dycv3rx7%252FerEC6oROldAD02f6ffLrIzmv8aSg87DLPcOkrT0buHupE%252F8GTz4i2VRuP%252FkSQu9Q2m1idJqA6WVQWnNdE6Alvp5cAtSuQWZrODvVWPK3dE%252FrUdbpHRkWfuwFW%252FzTzLzDmDVvwKxQ0%252Faa5Iu496oar3zpChbieKpN1FTn8qpG2acLfMcHOBlvCgvOyqffjQQKevOZrMilsTl1cHtGIAr20AIb1pgnhVx0S5QxrflMo8PWpse62verkCe1RqH09xg4DTL5l6SnjTm1GF9ophADOSkr9hjqjbGJ8%252BlZdSk%252FgZzmXcMAkMSzVqIz7zuZN1igYI2cD3urvpZ%252F1Uv9%252FS5PrdlKo9BFmk9SIYqSxTWPDltgu866mhPwdDzJC2Ss0o79ADLENuEWW1gsUybIRMYU%252F23HlOpLUov5rEU8hzC0MHkPCvrIJ98jOtfh2NvfQuIHh7KBKDH9cYoVZr%252BNpfY07iQoUWR77J1BtE5j7SYXnEogCKD%252F4QJQ0b5l0leR%252F3nGi8y6KoANzGItvlGzs%252Fj2byabKdCptIWWtxjKTdpHrUWJuq6A7RYxGfLeZS%252F6MhOkujwOrYt3ZNdpaqaYiONBUT3zipjj8icayhv9kq6MoxVIcDCQKtAbuhqlsdFGksbAxoy3PuAuCIze2UuE59fxCqBJOlFC1eNlWvXpCQmfggxCPNpi1HFDMy7CoVkoqz7Krk9OGitufJIw4LGa2uXNNkh8NrK6qhFoSITg2c6p2sQar2j523abNy9%252BrPNypXw2YEa36ioV1XEV4tydd%252ByYkNJYCnMetxtYKvCJguqr7v6tdWeTQHlUkLuXw4WZ3kcD9obMF06vVpbxyJ%252FGbV0y32V7GTOeUqmyA5jvQykBpNxZY%252F3tbh%252BtQkZ%252Bpnt%252Fuk8y67w5kdk8yPaq4%252FdDV2NUlS06qHiZSyJVbFEOnnnIdEeCvMhbR%252FiKW3jge5SzXD4ux77pGZCrSYjRc%252BQ1PPH1kcVeU%252Fny%252FwlVB%252F3kGtTvf%252Fz1U9vX73%252BcPKP3155YSOKp0%252B9b2EJr7yMJSexdxOtvJsYAvG5qqrV%252FWzW1PaFQ1lf5fhs3qQy1CaeTr2vsVMV%252Bt0bWyv8ztCVOddW08vaulPGQ%252FmoC%252BRIv%252BpU3zoVS2Vc7xAgw1a%252FVofS2jS1GfOpUrjF8PR6%252BOJ0Q41947YnMcrXG%252BNx9wpM4M1yXiaL%252BUqpG1SXgUWcVlenbSq28XOql3rgHxfl5YHEZzIkzQEYUdCP9FlHHea6JbWc1Kun1%252Fz3EiOMrxJF5bPvx6NFsojnYPt%252Fz6PF5ej40yiF7FKdGCXn4LDg4IhwxjkiLMShCDg4dLlaSCev%252FRBuNMFZErgdHfvj0Wp0PAn43Xh0HpWRvD2PTuP5epIn11mTWicpuDfLrkfHjI9HaRzlo2OojuCe%252FIURAooZyCaBpX6HDfgYAYarOCrATs7lMjfJeQk4sE%252FGo0slEbjgIUwrYllnylGzaF7EwBlIBwhd1DdkBKsh81CwUPCQhT6jYUgdIE9CpkBTjpxBy2QMV3K2UJOBxMfRMQAvo%252FwiLv8ND3Bz8R%252FA0fz%252BDR6gaTAeLRcwBsm%252Fq8fLBTzaS0aU%252BMNk5AdChD4njAY%252BImG4hlWdOvZFFGCsUFolVE1qBFRdnYCTncXfQ1Z5ax5cOkIkpGMGbCBEIUCdhJIgDJGPgjXEi%252FkELPYijyyWgHFY4STIBnQ9tQLrqiyqIRHBMCDM5z5mlIVEUD%252BkfLeuhKh8mBCbD7srS1UAeykL8WEYUUBCPwgDLlCIkB9gB6clotIUGxCp5DGjs9J0DwsGWh%252F4FQk4I5ihkCBfw3MVneVZHw3DgULjW9GoSQ2WttyP0wEWyDT1YDowpEL%252BYBT0AvFCcOS7aAfVeWRASC3zKC3mUZ1IbvcMhoMTBkwATIRyDnFUcCLcQkXI8BaNfYlIAQmesYBxX%252FiYYqIZHXjyVXy6nM1s4QLMQQBHCos16mmz27BxFs3j76OzMstV7srjIvkYv5EPj0dvIfPHhdyEJoU6vHwTLUbHZb6MXaVAAj2YDNQnY1hQJCgGMiIQhDlktzpi2vE7RUzt2GSfkBmQgUbrY0BGOeGIAVQ9v20E6VcGG1gN1gmkeQizV3IgeKg%252BASEjVIQYUcqwS0VHeKVQKDoHl3TbKlgVlphW7zGt3kNauYe0cg990VoPJMeFLILAH1BIMRsgPjFAev1dQIC%252F3C5A%252BAz5kLBCBGYPxa5rLATzqmOhvXraNxZ%252BlsgXQPEkAsKglEIQEoKdVQcBv9pS7trLDnnK%252BC4qiv1qDzqw9oD63Uc8gF2dwEGAtPL3JkkhGNmMFzf5jFirj2rioLwsNLUwNLB6grod9ltBSEJCfLI7UBNM%252FS37UadIrZ2p7hWk6cDag4DdQQ0fCiz1hMRulJjQbSWiE0rtpPKz7FM4h%252F0yp5wJHkAkC3c6GG7q%252BslX7GGYceoLRBklOOTcNVRysXazPSKlxNONla8TlS0%252BS6jk8nAAByRgAofI57s1Cf5baRJb7fVr0CQLAvBDqOd9SPOMYt9VlaJV5YTutQUAK%252FqS2qQBCyDfyV2c8GlAHA5JoIDGNeL%252Fn%252FgjaxlIJiFBmDMUaPFnYymHm1puMuSgRB1%252Fw%252BV1NF%252FGUr0I%252BfvUbaEYaMECtBcI5oNvhtjpHGgN0L57cwZIHgCg3ORuVaCAEkawgIYhlALU4eCVELnrUBnk67JT%252FeCBhbAbhciDGPix71psE38ddvCeOQR%252F0bgjt5c%252B7DTgX6iYArT7nI%252BAF25T5%252BdKI7r2wBpBjBTKGoyw73a6Vx%252B%252BTti9fA4%252FXkwBQvJlmaobViiH2NQRq57%252BEKXncznmw4dsWS6WktNqC7%252BxZaKetvM6G2Al29vVRPLw4UN%252F2WaRSZ9yh45FbRoYS6%252FrgcDUZyEmDHPBLTBqCtsBWBhxA2Dp7hgAqtdgTADmgjoAg2ZNYTsAS3fmgQDU71%252F0DMlYcAuAmsJ2ALbWixMCW1%252Bqi0B1W%252FoIeitqEEyiNYntEGzNliGSvoizq7jMVxZeTdIWKWuzdzhrv4vyQM6qXiqzeaux4hZvbUjcR9LWRsp9RN0j6CxrGytOwrb1ULoQElt4762nidokmeyO67YWhhP7DirYFFfMJTUEPapOkcXWongoEBuie2%252FJbSDc4rul%252BeAGwtagccqxvSV1ECZVpyxrMWoDQzY8urcfPlggmAtm1uCuU9ihBUsP46G0sL1sMxfeposBhdvegHYnA%252BPDs4GgTPp9ao%252FkL47AfhnuM1ZIvzhVp%252F3SwQmLrfnkkETM5TQMJkWHHGJrBq1ZtLVVHFg0iU76lBxYs8hnVzyyNFGMYjO%252BtfBrrlQFIoNYNXVH8dZb38kSNiphVzo21tNMwSTplIv3kLito7O%252FyE1qLjK3cOAkdFuXxkno5oKa1E2aTlLfyMhoU9%252FFwQVNopM%252BJQcXtCx%252BbxdUp4w2sRprWZ2wmbxDopa2jVa02PofLiI1qE4spBxkautCuBnsJlS7DLa3om6xBlEni93DLKy9F5dAYTeLHjmXSGFT%252FMOYM7EVG%252BZqmw2afDlHxPfyRLy7vuj3opyM3cFems9LbAWIsapm8D3CGpkd5tPvOjlB2Z0ityAxF9WQmHSdgVgaMQ9jTNS2yTMW22xMdPdZga2Rop3KWBpMLqcyJtVJn5RLJd1v2rltPjeC2hXXzRX1XadJ1Cmu7xMgbb1Kl7i%252BITya5FziuqU15VZ272R9i2Oai%252Bq1t0F3i2O%252BvxtXzbyqA9V5aR%252FWTIHga9ktq%252F9vPxcbP%252BHiPvNFABU14Rz2hdrrmy3yuv121%252BvTUcKb12Dv7I01jtaNNT7wxTYBvg5myCB%252BURCX1jhU8Io1Z128n%252B76nE44R%252FrrNbuagP7A96V9mA2RiULpDMqlWqNWO1M23yxArGbJ%252Fop%252FPdHocr6pT9LrHuiP13GeJ5VO64N62eOUP07yMxh%252FtjyNp9npn86deSS03q4%252FsGONOBIkREKggGMO6vOHSML6TdTDiKFYXMb5ZxWE8EOMQki9IA%252B%252F85nAbkE8qkVcZel%252F49XnEwVGBCoR3wc5sJBR4fKG%252BARW2eYcLl%252F4rNQr8R%252FluxCf8XOfkATyCBr5mEEJHAzBuu%252BnTPIVyepTUVrh3eu9h8FIqYANINRh8qNGDnl4kF73V%252Btt%252FW7nR%252FU2vCQ1ZY%252BId9OLHlYHd9uOWzKuQ7WJoOANBWyxIBUSFDLtWN2hyLQG5sdkNwB%252BMSWUIiQ9QQzi1pJOH5NXzGEWIhCmEOwtBA8GMWuLb249CUvR4NZ5F1A88tDn2IdfnW4wgXtQliEsG5GwV2Vunfd%252B1HJCYE%252F3bhhgHg4YbLNB6AELBe3stUMmEGykkOAQXRxB2AKSIwxbsnaEobwywBx2JRQFOoqQgpcy7oMHgFGGfBOK93cSSP9tPLOOr7ZzW6t5AeyAAkNOoXYOkPYt2%252B5qntUl8mPU8hi4CbgP%252BhYcJKV%252FZr5HMV%252B%252F4%252BhSyAcDPzQRAbDHEEY%252BmKRwLOSxP9U3Qo5124nStPevZXRur97eO7%252BOSe%252Fx%252FSNkFMJ4AFGDwqaTEM1mtn2fDP61uWb%252FAl8nC4j9mAjwuZD5Pnf4Krf5PsiuNLcPVrX%252FJ9Y%252Bbz67fZa7qQSxac6tgWyJEg5pkhIWcs4xBHvIVojzQWnS4llup6A2%252B3R%252B7QuiFoQbGgaCq9pJPwft4XF%252F%252F8sSzgww9bnZMCDW8zp1BGdj16012%252FeLhxL7hrekIAvyQGAQdkCgyN4m8A3vSEFCfH%252F3PxirbLE%253D&embedded=true&startPaused=true&defaultSourceFile=bloom.frag"></iframe>
<p>While this is probably acceptable for our little example here, truthfully this leaves a lot to be desired. There is a lot more we can do to improve it such as using <a href="https://learnopengl.com/Advanced-Lighting/HDR">HDR frame buffers</a>, tone mapping the bloom layer, or having several individual upscaling stages where the layers are recombined. If you're interested in learning how to implement a higher quality bloom, <a href="https://www.youtube.com/watch?v=tI70-HIc5ro">this video</a> is a good place to start. One other thing you should note about this example is that we are using a nested loop to achieve our blur for simplicity whereas normally a predefined list of offsets and weights is used.</p> 

<h3> Depth of Field </h3>
The last effect we'll look at is depth of field. Essentially, we are just blurring the image based on the depth of the objects in the scene. We looked at out to use a depth map in the shadow section but in this case we will be rending the depth map from the perspective of the main camera so that we can get the distance from the camera.

<iframe height="350" width="800" style="border:none; display: block;" src="https://jaspwr.github.io/spectra/?startIdle=false&project=eJzVXHtz2za2%252Fyoc9R87kRQABPhwbnYnu0m6O5u0ufbd7qsZDy1RNluK1FKUH8n4u98DgKRAEJRA2XHadJrwARyc9%252FnhQX0ZZdEyHp2M3iSLxWYdj8ajyzxK16OT%252F3waj9ZX0Twu%252BM2X0SJJ46rtMkqy6XVclNB6lmdlnJXQZvQdPFoneea4CDnx%252Bufs5yzJnOt45jqrfJ2U8Orl9lGWF8sobR4QZ3P9knfZZMkCXjnLqKTOMp%252FHvE3r4XUS3%252BjPVkX%252BSzyrhtDepcnlVfmToZN48bHdM9%252BUkr%252FrH2oGq0fEuf779fYW%252BPiYr1v37zm9v0sxrvNk7nBFHR07X37OHPgD3Z1XUkxxKweAR0dCTOeZIHMkFTN20PT4eHp797luDqNB21bTWq1jB0%252BP63YVF9BWkw96NargFCT7vM9lev6xIgXdVmqP61bj%252B9H9uOsKiyK63OsKqyKeJeLZFTCxchZpHpUvVSfZarx2Calwedfou7lV1d0Y4R3w8uc8zYuWH6yj5SqNC%252FLG4S6d33yIVi9Nb7Nl64Xg0SmTZSyoyVtJQTGrcHDQ2Z%252FzvJhzG9Wcces5L7a3N5W6W42Vm2dgc%252BY853%252BL8Xjb7%252BbxIsli5%252Bwvr9%252F8%252BI%252FzD68%252Fnp%252B9%252FvDx%252Fdszx5ctVK6AHpq%252BVJ%252BXeRml%252F4g5B62XeeEcJVnp3MLTSZf4S3jxP4ZB4fnz543oLUp3fZTueijdaZS2TBcEaInLo1vQyi3o5A7%252Bvat9vN36dNvaoKVnhrGPG%252FXWf5KFcwSj%252FgGIHTvckZNsE3dayfHmybpsNIqnzkR0fcG79vSYbYoCIuNNvCqvWiafftYkEm6fLxbrmBPnd0e3YxBc%252BAZCuG%252BANF%252FH62aAMr4tN0V81Dj7WB3z9g70Kcc4nhYaAxd5njpJdla7U4v1iWACUdCTOmKHqcoZn7%252FinlGR%252BiP0pc4JKAxxabZKfOm0O6seCxSUhtt29%252FKy%252Bqca7sUrtW%252FDVBGDLrKqEc9hfel5W5W46qvs%252FLxRJs8NY56S6qysdAP%252FL5Jsncyk0dwjzPO3%252BMs9bjddb7K6ERo7E8z%252F3zaR5oyyyzTmyk8hMx1N5nlZVYXkc1xdHY%252Bd7SOgeXzMB1MLQe2soq7%252FqeA6yeI1TzmCfJurGaTzIlKKgGBwEgBFCv8HU00KXhbeJEVVJl4pvPAsLRLfRCPaFCjev4gXqexspkKm3EcaucdcbdxtKvtMxH1L0PUqnm3SqHjd0h0n0eJ1bBq6oztpqYpirY0VZP3WKFw3x7rtFm95hENTkRkM4zf2Y5qpFkW8zmLufECDVwEPBJZkFm%252F1YeL5ZSzqSpJdNtKKtnzsihQXiR1DasJs2ogoUglmbXtCjRFuv0xuj44ab5aBqjnQeOvtnCbky21cPt8q7VkjjxhPbaPyvhVLcPDsVVNf67wg%252F27qurQGPRLta5t1cEm8XJV3DwUmPaDCkDs63PWwJWXjkOy3jZ%252FN6ZFag9DDAeV6VsTxoNkFVbXTQeuqLPxKQ%252BMN97Iq8uL0gkyRWYztMFBDdMaFPz7U47qIFKqPEalepHm%252BxP2vSP8rt4Ow7R1dtBJUFJgheZG1UUQ7Vcqm5EZ5Gegv3eYlnrpNPlBDqm4O%252F1Ztn1dMVLnMMXiSaPC1DSKT8UW6Kd4ATnmAYmuc%252F7e3pz%252B8fX9%252B9td%252Fv3XCWhcvXjh%252FgiGc8irmnMTOTXTn3MSQm%252BcCf4vn%252BaKeBawtJgCy6udpg0WaWtSaGSjsyClB%252B8HOuUCr6Z3e14T%252BOQpvAX4AmqpCnql3LZyuUjFg6GouAUVXXt0dc3dTzKb1d4XBDZ6nIufLix40fmM3e9GA7o32un0HLvBhk5bJKr0T5gbT5eARF%252FLuoqnOJn4uVPAH8XFZXh1x%252BXSGuDsAI0L0Z2qvZy3m2uCbd%252Bog7y3%252FncoI7WWlMMXsnE8nfly8S%252BJ0bhe63yULiBzn%252B%252Ffnb8%252F6A%252Fm7OAMcs60Z2%252BpgWCGAK2PynFdznZ7Vgb2x3i4%252Fpvhrov3%252FwKZiOIe701UyuxJmTpbRJQR%252FkqbOBdxlEHCzTSvaxQMR56FPO4sIp04weG3gVMb96b5oP5Uxfmo5r5fh%252FdwREWKe1xfR%252FOy%252Fm6iI502vU2h92p1l1%252FnxJgGNzZJCItBf4wLg59T563KVF1FWCoYv8l%252Fjq565%252F3bA3bll1iz0iITQmaVTi4TCb8cVJXMuqd0AElSUzWKA01DvuBeAjQEpr9Ioi%252FuWJ5SBhBspIxlVXWdCPjm8WB8JEhPpTFwo4k1N7L1LsrlzBTPv5QYcNF9I7sD7lxCvvD6BKh2IRXDU8ipZO1CQV05SwpyQw6gOuYs0jkGt4FG5kdK8iG74bKcml0BszQykKu%252BBMOTT8fV%252Fi1KuzyjmNSrhpo4EOZlq5nCCEs9ZL%252BSLWlnNjKo1feyI9Xo%252B3%252BZokU4r%252Barx4A4wb1TGJt8clsBvmmLCmb9Qpmy%252BmPdV7znQoh1W9XKkr7nwP%252B0K0WliURn2VQVRFD6NR6tkFaeQs74votXV6OTLKIM5h9yJSOZQCgBkIsIoY4jQEIeBz6BUlHcrXkWqBA0PasjOCdyOTrzx6G50MvHZ%252FXg0j8qIP06jizjddnL4OFtS26kLPFvk16MTysajLI6K0Qlf4Bkt%252BBVGCCjmoO8EhvoPmrIxAhmWcbSGEJzzYW6SeQlyYI%252BMR1dCGXDDQui2jvlyBG%252B1iNJ1DJyBcoDQZfWAl8hKZBYGNAxYSEOPumHoWog8CakQ2mXIWmg%252BRYM76I1FX2D5MwgO76PiMi7%252FCaLX1%252F9Srv8trjerf1b%252F%252Fkv036z480PU4xJvmHo8PwhCjxHq%252Bh4iYbiVSG5kdbXjYymhUTmyU60beXcGoGsWvwPE8oO%252BF2YpIiEtD6ADRQwCsCRxiR%252BGyEP%252BVsTLdALOellEBifAOKwsiUyCbrtKYW2N5SqSBP4wQajHPExdGpLA9UKX7bdVEMjwJcQUvvbGErDyIGMRPExG5JPQ80OfBShEyPOxRbySQFqKDkhSHIJaG02NMH%252Bg90FcEZ9RgikKCfIUeZbRrMi70lDsC2k8ozSiUy1Ls%252F4TZwM8kCrmwe7AbAqlg7pgF8gXAUOejXVQVUIGZNMSsOc6jaoacntgMhxcK6ADyERcxiCPBowEdqkipHiHxb5FpoDaTqlPmRd42IUY3MoBkbyMLzaLhSldgDsEwJGQxZj1lN5N2gBgHb%252BLZmVeiNpVxOvkc%252FyBvzwZ%252FQBFP17zVclkLba9PkSr0UlZbGJbLRBfsScaaE9KceCiwMVAJvADQi2qW5UxzfJbZUxlHf2QlOmTgU7rYZDMZYQhCqKq9a1XSE86rG90WCsh9VX5JykOlIKElLhBiJHrUmwD5giTBgW8ORjN7QKvMi3JuvM7wXqgORZwEATxgEIX0wHqCwZorzsB8PG3mwAEHkUeFKwQgdsD2LXNheBeVS40o6dDc%252BGTZD4fwFPgEwpQCkFK8PeiDgJxtQPummEH33b6GK3Xh2EPdyj2ANQLsxU%252FJCEhHtmf5gh2vR0TOas8p2xRHZTi3IGVm4DVAAGHAbgq9lGwX0pM3F0Ay0pKZd%252FnICkRG2hKBrNN5jIaMB%252FyQLjXPXGNiie%252FXf8EiM9cL0AudQkOGbNNNCyoQZfRgPvyDJennWneJyLXPkmiYXxqjX3i0wDD7JrttyTEr7QkNor7W7Ak9X2IQ0DDHhRJ6mLP1pRBY8qJexCABi%252F6ltZ0fepDteBzoMBzfWKxxADwE1cS%252F37yD0cCUExgQo4ZRX5oAYRwjYQmQ5YZxFo03F5H6Sbm5kXIOwT1hMFADw7Aen5APYjNEFutomwFNM99rAUkTyEgzOcQC6jvhiFgAddi3ZIQhKoS8ttyVHXeTkOYzEHqQRQC2bPFqsTb5h18EFgFWP5NEw%252BfnXkA1OE%252FgEw%252B2r9MRiAMd5nzqeqIaj3wRlCjC7gGI%252BzZLY5Va5cT%252BqCgw0%252BSVCAxhHyBFsApCbG1dzLvcWdST4pvPJf5Ll9DC0IoGfvxDQkrfEMGrN8%252BLbxBLORrYi5hgR%252BEobpiZDsldo3C%252Fc6WB13Xd%252F2QAlILAo%252FvgFkUkXp9EB%252B%252BdNY9sPMki2cB1EnqhyFDlAD0VhZ%252FbpJsnt90hXVxlWLNWFZ2G7SoHSjmomhnMnWhuoOfhoDPgGtmt9RXJdMhG7dPthHkEQZgzGc%252BJSBTaIM5PbRr%252FaJHHnmGhT%252BQV2fFjDtdUpTn2fSXlbW3tYQlyGpVGijxg%252BryzMFaOP6o59yBfPuXKJunvM35eb4pVxueC%252BRq6ahvd1q8bfq11hqFpm%252FvJpyH8%252FPusPUgky7lFh2DVyrCGE4UPJIw1bKzLoY%252B4A4xKgq7BTAwYieAYSNdE0AeQdcF0AdUBdBoVhR2C2DYCH8kAarzkx1H0gbcIUBFYbcApl1uKwlMRwDaEoh81pWgM6Iigk60IrFbBNO%252B9hBNX8b5Mi6LOwOvOmmDlpXee4K1u2H9SMEqPugwRas24o5orUk8RNPGPeuHqLpD0FrXJlaslG3arm6LkJjSe2c8RdU6yWR%252FXjftFluxb2GCvryiD6lI0KFqlVlMu8GPJURPdu8MuUsIu%252Fxu2Oe1E8K0F25VYztDqkLoVK2qrMGpNRny4dm9%252BTrZIII%252BYG5M7iqFPVYwbBc%252FlhV2wzZ94F22GADcDhZofzHQfjZioFA6%252FS61rxQvloL9NDxmjCL9ZIVOu9DBShbTPr9FEdGHU2TQKVrUEAMT%252B4LesK2tIbr41sC3PpKMdo2Y7LoHIXXGt1K36YSBVc3TxlP0rZO0KngHaNy0x364ynVqNjo3cGCldNO%252BuZXS9QEVres0rbTey8iobyfcIhR1opMuJYsQNAz%252B4BAU2z4mtWpjGYOw7rxHo4aNdAUZmHakbVSqUZ0YSFno1LQvbOewfVLtc9jOiKrHakStPPYAtzDuhtskCrNbdMjZZAqT4R%252FHnYmpouuj9Ts0%252BXaBiB8UiXgv44bTAVbObuEv9XdwBgn0URWH7xBWyOxxn%252B45ACtR9pfIHZLogyqS6HStBTHsjD%252BOM7mmmZQ2WL8zufsn5KadbWXpw7Djb7P0oVOddElZ5HXDKQq7GV6vUPvyuj6iOrXTiVrl9UMSpOnwiE1e70mPOjmbvG44K2AHu%252FeyviMw9UFV7K3RtQ7M3nnAqO%252FIgIV760QnXUoW3n3oTNK4P%252F6wqWSHpA3oMmxP24Euw5kFO9Clj6iCLo2o3TShj5NR3460DabViE66lGxWe7ueuRcPms4LaOtz0dK0NKcPVgFCnV7Ve8%252FekcE7H4FzcSrBwHpnuB7e6%252F57fLq7q28HrfYL0LPxpY%252BowiqdqNXGl2Ef%252F5G27vivJZrSijbgjp07QeH%252B0%252F1YnjOS%252B%252FCtr0SBfAZ93%252FMzBNUvFl%252F2%252FlwA86gX%252BJ4HiJOB6ZUjI42A1aGE%252B%252B7hEcLq767uzecLGNqeL2CGwyA7D7MAGAODUgCYLtQz5aidEG%252B95awt75f7LqcTxpB6In3fWQhv4Ad6HvQG87gehBImrnK0UdlZ049aIVqxZP6mtOqonf34UO0nVidDfryOiyKRNq22K%252FlRD34hD4XM8iye5he%252FWB9AQoFyAMkbeNwKMQTJD2IN%252BQwzMJ83RBPGj%252FAfRw3LPPs1vntKRQReiCGSMVQE5LW%252BS92viK%252FrEZuLJ%252FQIjAhMFD0PtEAhDwc2HyROYJRdoWHzQfmd%252BALzM%252F9mQXzGOTnoyPrgLxFD4vNUjSBl45D5Q4Q99NN56Jpt0lRIKS8%252By4snEdgNEMEwXea%252FpcFgujTIvuYPvSx%252FLwBL89ZfGn1FafuOvBmD3BK%252Bd6uuBSxGIQF8SQAOuB5BIVU2GC3gsDE5f012feAXUKUL6IuHQzCIW0NJ%252FZq8Yga9EIFkhfwgCJg%252FiFlTlrPbnTUAB7szSDAPBdDrMezBVetcDIFnAM0Q5kcyEKBeuzNI3dRlOZM2lXw7GaAf9ilmFJTuU5iEtBZEQxogmEuhgEFusRTClI4sxTAVbEsxRFT6mPlgS%252BSrUoQuRCllMDfE4JQh65Pi0z0XpPuxgI7l5bR%252BJ6IPgB0wIMyDAD%252F7SDlVvR%252FR0womfw08j4Ebn3lg74CBptTfNjoA0FfH1m3AvD%252Fw%252B%252BwA5mGEIow8cMnAEsxjb6pOhiyx25mwtPO%252Fm2huRnCfrL8WcR%252Fw3QBUFEKZD1nDJR64j%252BIzu34UB%252BKrH7d%252Fg5%252FECSD3YxJAzIXU85jFT8HUn9WbjWb3KynKL3Mf8pGH3W%252FB9EEQk%252BXsjtIYsoRFmXQJDRljGJI9VCvE2KAyaYgsu60qk39aH4CFrAXpxg39gAnspG5WdeSxPwlrSGeaMNX66TBBjOu2Yp%252FExK7d%252BZluXDyW2nvOi0IVZH6AQdk%252BAZC9S%252BE9p0WhIH66%252F38XjnN2&embedded=true&startPaused=true&defaultSourceFile=depthOfField.frag"></iframe>
Once again, for our introductory example this is acceptable however there are some improvements to be made. At some resolutions some of the undersampling artifacts are visible. This could be hidden by using a Poisson disk sampling pattern or just increasing the number of samples at the cost of performance.

<h2> Further Reading </h2>
<ul>
<li><a href="https://learnopengl.com">learnopengl.com</a> - We already linked to and used images from this several times earlier. One thing to note is that while it's a great resource for learning the basic, it does not teach very up-to-date or modern techniques.</li>
<li><a href="https://www.youtube.com/@acegikmo">Freya Holmr on YouTube</a> - Many videos covering shaders and Unity ShaderLab. Mainly in HLSL which we did not look at here but once you know GLSL it is not too hard to pick up.</li>
<li><a href="https://www.amazon.com.au/Real-Time-Rendering-Fourth-Tomas-Akenine-M%C3%B6ller/dp/1138627003">Real-Time Rendering</a> - A comprehensive book on real-time rendering.</li>
<li><a href="https://developer.nvidia.com/gpugems/gpugems3/contributors">GPU Gems</a> - Several books published by Nvidia available for free online.</li>
<li><a href="https://www.youtube.com/@Acerola_t/videos">Acerola on YouTube</a> - More light hearted and less rigorous but still a great place to learn.</li>

</ul>
